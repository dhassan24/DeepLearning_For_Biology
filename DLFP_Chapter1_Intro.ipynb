{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr+vN6fxs+j09o4xGbiZT4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhassan24/DeepLearning_For_Biology/blob/main/DLFP_Chapter1_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUv3BIBaDKyU",
        "outputId": "6a07ae17-6306-4d5a-be19-944465cdad08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepLearning_For_Biology'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dhassan24/DeepLearning_For_Biology"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "m9QyOW2NDZsc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "#Mean squared error, a common function for selecting model performance in deep learning\n",
        "#Since you want to minimize the error\n",
        "\n",
        "def mean_squared_error (y_true, y_pred):\n",
        "  squared_error = (y_true-y_pred)**2\n",
        "  return np.mean(squared_error)\n",
        "\n",
        "#Example of usage:\n",
        "\n",
        "y_true = np.array([0.8, 1.5, -0.34, 1.91, 0.49])\n",
        "y_pred = np.array([0.25, 1.2, -0.07, 1.32, 0.67])\n",
        "\n",
        "print('MSE:', mean_squared_error(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oXcfsk-D3pD",
        "outputId": "90c5a3f4-db21-4ccf-e138-ec9ea248e696"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.16917999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3MQ61TUEj9t",
        "outputId": "24b1015c-d19b-474d-fc36-f47fa76620fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.16917999999999997)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can also imporve the function by adding hints to specify that the inputs are np.ndarray objects and the return type is a float"
      ],
      "metadata": {
        "id": "ExBV4tLZEl_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error (y_true: np.ndarray, y_pred:np.ndarray) -> float:\n",
        "  \"\"\"\n",
        "  Calculate the Mean Squared Error (MSE) between two NumPy arrays.\n",
        "\n",
        "  Args:\n",
        "    y_true (np.ndarray): The true target values.\n",
        "    y_pred (np.ndarray): The predicted target values.\n",
        "  \"\"\"\n",
        "  squared_error = (y_true-y_pred)**2\n",
        "  return np.mean(squared_error)"
      ],
      "metadata": {
        "id": "RAulNRR3ElA8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decorators are functions that modify the behavior of other functions or mtehods; used to enchance performance, cache results, or log function behavior.\n",
        "\n",
        "One of the more common decorators in JAX (our HP numerical computing + ML platform) is jax.jit. It performs JIT complication to accelerate code execution."
      ],
      "metadata": {
        "id": "1hUs_TWvGRpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ex: a function that takes a JAX array, raises all values to the 10th power,\n",
        "#and then sums them:\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def compute_ten_power_sum(arr: jax.Array) -> float:\n",
        "  return jnp.sum(arr**10)\n",
        "\n",
        "arr = jnp.array([1, 2, 3, 4, 5])\n",
        "compute_ten_power_sum(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPFtqPEGGci1",
        "outputId": "ac4b4800-fd5b-48ce-f930-aaa69157d060"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(10874275, dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can speed up this function in one of two ways:"
      ],
      "metadata": {
        "id": "1foTTo1jHJYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First way to speed up JAX function:\n",
        "\n",
        "%%time\n",
        "jitted_compute_ten_power_sum = jax.jit(compute_ten_power_sum)\n",
        "jitted_compute_ten_power_sum(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rab09VBKHLsQ",
        "outputId": "3aad879f-8638-4959-f63c-c906ad5f2ed2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.62 ms, sys: 69 µs, total: 1.69 ms\n",
            "Wall time: 2.44 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(10874275, dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "@jax.jit\n",
        "def compute_ten_power_sum(arr: jax.Array) -> float:\n",
        "  return jnp.sum(arr**10)\n",
        "\n",
        "compute_ten_power_sum(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvVP0oz2KxKJ",
        "outputId": "4790286f-f03f-4da9-e58f-ca12e4daa1ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 46.8 ms, sys: 593 µs, total: 47.3 ms\n",
            "Wall time: 46.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(10874275, dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@jax.jit applies --> then JAX first traces the function (runs through it once with a special tracer object to build a computational graph, which is the static representation of all numerical operations performed) --> JAX compiles the graph using XLA (Accelerated Linear Algebra), this is a backend that generates highly optimized ML code --> compiled version is chached and reused whenever the function is called again with the same input shapes and types --> SPEEDUPS"
      ],
      "metadata": {
        "id": "yQlWHQJLK9Vd"
      }
    }
  ]
}